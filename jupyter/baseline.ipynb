{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd71461b50b54184",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T09:21:39.207095Z",
     "start_time": "2024-11-18T09:21:39.197093Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66aa071d1a63c5c",
   "metadata": {},
   "source": [
    "## df 节省内存函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da18e3e07c0cd4e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T03:17:22.269407Z",
     "start_time": "2024-11-18T03:17:22.249353Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem(df):\n",
    "    start_time = time.time()\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    # 返回的值以字节为单位，转换成以 MB 为单位\n",
    "    start_mem = df.memery_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_max, c_min = df[col].max(), df[col].min()\n",
    "            if pd.isnull(c_min) or pd.isnull(c_max):\n",
    "                continue\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memery_usage().sum() / 1024**2\n",
    "    print(f'现在数据占用大小为: {end_mem}')\n",
    "    print(f'减少了{100 * (start_mem - end_mem) / start_mem}')\n",
    "    print(f'花费时间: {(time.time() - start_time) / 60}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f0e566ac3ab59",
   "metadata": {},
   "source": [
    "## 读取采样或全量数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747c31d724f04899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T03:17:24.119842Z",
     "start_time": "2024-11-18T03:17:24.099940Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_click_sample(data_path: str, sample_nums: int=10000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    训练集中采样一部分数据调试。\n",
    "    \n",
    "    Args:\n",
    "        data_path(`str`): 原数据的存储路径\n",
    "        sample_nums(`int`): 采样数目（这里由于机器的内存限制，可以采样用户做）\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 返回一个包含采样后的点击日志数据的 DataFrame；\n",
    "                      该数据只包含随机选择的用户的点击记录，并且去除了重复的点击记录。\n",
    "    \"\"\"\n",
    "    all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    all_user_ids = all_click.user_id.unique()\n",
    "\n",
    "    sample_user_ids = np.random.choice(all_user_ids, size=sample_nums, replace=False) \n",
    "    all_click = all_click[all_click['user_id'].isin(sample_user_ids)]\n",
    "    \n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    return all_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7cb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_click_df(data_path: str='../data/', offline: bool=True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    读取点击数据，支持线上和线下数据的获取。\n",
    "    根据 offline 参数的值决定读取训练集或训练集与测试集的合并数据。\n",
    "\n",
    "    Args:\n",
    "        data_path (`str`): 数据存储路径，默认为 './data_raw/'。\n",
    "        offline (`bool`): 是否仅使用训练集数据。若为 True，则只读取训练集；若为 False，则合并训练集和测试集。\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 返回一个包含用户点击日志的 DataFrame，数据中去除了重复的点击记录。\n",
    "    \"\"\"\n",
    "    all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    if not offline:\n",
    "        tst_click = pd.read_csv(data_path + 'testA_click_log.csv')\n",
    "        all_click = pd.concat([all_click, tst_click], ignore_index=True)\n",
    "    \n",
    "    all_click = all_click.drop_duplicates(['user_id', 'click_article_id', 'click_timestamp'])\n",
    "    return all_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a59d14beb34c15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T03:22:46.978519Z",
     "start_time": "2024-11-18T03:22:45.956392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199999</td>\n",
       "      <td>160417</td>\n",
       "      <td>1507029570190</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199999</td>\n",
       "      <td>5408</td>\n",
       "      <td>1507029571478</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199999</td>\n",
       "      <td>50823</td>\n",
       "      <td>1507029601478</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199998</td>\n",
       "      <td>157770</td>\n",
       "      <td>1507029532200</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199998</td>\n",
       "      <td>96613</td>\n",
       "      <td>1507029671831</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630628</th>\n",
       "      <td>221924</td>\n",
       "      <td>70758</td>\n",
       "      <td>1508211323220</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630629</th>\n",
       "      <td>207823</td>\n",
       "      <td>331116</td>\n",
       "      <td>1508211542618</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630630</th>\n",
       "      <td>207823</td>\n",
       "      <td>234481</td>\n",
       "      <td>1508211850103</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630631</th>\n",
       "      <td>207823</td>\n",
       "      <td>211442</td>\n",
       "      <td>1508212189949</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630632</th>\n",
       "      <td>207823</td>\n",
       "      <td>211401</td>\n",
       "      <td>1508212315718</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1630633 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "0         199999            160417    1507029570190                  4   \n",
       "1         199999              5408    1507029571478                  4   \n",
       "2         199999             50823    1507029601478                  4   \n",
       "3         199998            157770    1507029532200                  4   \n",
       "4         199998             96613    1507029671831                  4   \n",
       "...          ...               ...              ...                ...   \n",
       "1630628   221924             70758    1508211323220                  4   \n",
       "1630629   207823            331116    1508211542618                  4   \n",
       "1630630   207823            234481    1508211850103                  4   \n",
       "1630631   207823            211442    1508212189949                  4   \n",
       "1630632   207823            211401    1508212315718                  4   \n",
       "\n",
       "         click_deviceGroup  click_os  click_country  click_region  \\\n",
       "0                        1        17              1            13   \n",
       "1                        1        17              1            13   \n",
       "2                        1        17              1            13   \n",
       "3                        1        17              1            25   \n",
       "4                        1        17              1            25   \n",
       "...                    ...       ...            ...           ...   \n",
       "1630628                  3         2              1            25   \n",
       "1630629                  3         2              1            25   \n",
       "1630630                  3         2              1            25   \n",
       "1630631                  3         2              1            25   \n",
       "1630632                  3         2              1            25   \n",
       "\n",
       "         click_referrer_type  \n",
       "0                          1  \n",
       "1                          1  \n",
       "2                          1  \n",
       "3                          5  \n",
       "4                          5  \n",
       "...                      ...  \n",
       "1630628                    2  \n",
       "1630629                    1  \n",
       "1630630                    1  \n",
       "1630631                    1  \n",
       "1630632                    1  \n",
       "\n",
       "[1630633 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取全量训练集\n",
    "all_click_df = get_all_click_df(offline=False)\n",
    "all_click_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d99dbdc9a35a37",
   "metadata": {},
   "source": [
    "## 获取【用户-文章-点击时间】字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a1e6d498c382b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T03:42:37.218824Z",
     "start_time": "2024-11-18T03:42:37.209312Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_user_item_time(click_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    根据点击时间获取用户的点击文章序列。\n",
    "    函数将每个用户的点击文章和对应的点击时间组合成字典，格式为 \n",
    "    {user1: {item1: time1, item2: time2, ...}, ...}。\n",
    "\n",
    "    Args:\n",
    "        click_df (`pd.DataFrame`): 包含用户点击数据的 DataFrame\n",
    "\n",
    "    Returns:\n",
    "        dict: 返回一个字典，其中键是用户 ID，值是另一个字典，包含用户点击的文章及其对应的点击时间。\n",
    "    \"\"\"\n",
    "    click_df = click_df.sort_values('click_timestamp')\n",
    "    \n",
    "    def make_item_time_pair(df):\n",
    "        return list(zip(df['click_article_id'], df['click_timestamp']))\n",
    "    \n",
    "    user_item_time_df = click_df.groupby('user_id')[['click_article_id', 'click_timestamp']].apply(\n",
    "        lambda x: make_item_time_pair(x)\n",
    "    ).reset_index().rename(columns={0: 'item_time_list'})\n",
    "    \n",
    "    # 将用户 ID 和对应的点击文章时间列表转换为字典\n",
    "    user_item_time_dict = dict(zip(user_item_time_df['user_id'], user_item_time_df['item_time_list']))\n",
    "    \n",
    "    return user_item_time_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e537c87c2675a5cf",
   "metadata": {},
   "source": [
    "## 获取点击最多的 TopK 个文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f402b04b1326932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T04:03:38.947882Z",
     "start_time": "2024-11-18T04:03:38.937872Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_item_topk_click(click_df: pd.DataFrame, k: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    获取点击次数最多的前 k 个文章 ID。\n",
    "\n",
    "    Args:\n",
    "        click_df (`pd.DataFrame`): 包含点击数据的 DataFrame，必须包含 'click_article_id' 列。\n",
    "        k (`int`): 需要返回的前 k 个文章的数量。\n",
    "\n",
    "    Returns:\n",
    "        `pd.Series`: 返回一个包含前 k 个点击次数最多的文章 ID 的 Series。\n",
    "    \"\"\"\n",
    "    return click_df['click_article_id'].value_counts().index[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac6d727180047c",
   "metadata": {},
   "source": [
    "## ItemCF 的物品相似度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2888f1675cce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T03:44:26.107111Z",
     "start_time": "2024-11-18T03:44:26.096571Z"
    }
   },
   "outputs": [],
   "source": [
    "def itemcf_sim(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    计算物品间的相似度并保存相似度矩阵。\n",
    "\n",
    "    Args:\n",
    "        df (`pd.DataFrame`): 包含用户点击数据的 DataFrame，必须包含用户和物品的相关信息。\n",
    "\n",
    "    Returns:\n",
    "        None: 该函数不返回值，而是将相似度矩阵保存到本地文件。\n",
    "    \"\"\"\n",
    "    # 获取用户-物品-时间字典，格式为 {用户: [(物品, 点击时间), ...]}\n",
    "    user_item_time_dict = get_user_item_time(df)\n",
    "    \n",
    "    # 初始化物品相似度字典和物品计数器\n",
    "    i2i_sim = {}\n",
    "    item_cnt = defaultdict(int)\n",
    "    \n",
    "    # 遍历用户及其点击的物品和时间\n",
    "    for user, item_time_list in tqdm(user_item_time_dict.items()):\n",
    "        for i, i_click_time in item_time_list:\n",
    "            item_cnt[i] += 1  # 物品出现次数 + 1\n",
    "            i2i_sim.setdefault(i, {})  # 确保物品 i 的相似度字典存在\n",
    "            for j, j_click_time in item_time_list:\n",
    "                if i == j:\n",
    "                    continue  # 跳过同一物品\n",
    "                i2i_sim[i].setdefault(j, 0)  # 确保物品 j 的相似度存在\n",
    "                # 更新物品 i 和 j 的相似度\n",
    "                i2i_sim[i][j] += 1 / math.log(len(item_time_list) + 1)\n",
    "    \n",
    "    # 复制相似度字典以进行归一化处理\n",
    "    i2i_sim_ = i2i_sim.copy()\n",
    "    for i, related_items in i2i_sim.items():\n",
    "        for j, wij in related_items.items():\n",
    "            # 归一化相似度值\n",
    "            i2i_sim_[i][j] = wij / math.sqrt(item_cnt[i] * item_cnt[j])\n",
    "\n",
    "    # 将得到的相似性矩阵保存到本地文件\n",
    "    pickle.dump(i2i_sim_, open('../tmp_results/itemcf_i2i_sim.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2e132ca4d56bff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T03:45:06.966619Z",
     "start_time": "2024-11-18T03:44:26.874618Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [00:20<00:00, 12090.34it/s]\n"
     ]
    }
   ],
   "source": [
    "i2i_sim = itemcf_sim(all_click_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89778bb233d89408",
   "metadata": {},
   "source": [
    "## ItemCF 的文章推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f883cbaa715c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T07:55:10.105800Z",
     "start_time": "2024-11-18T07:55:10.093287Z"
    }
   },
   "outputs": [],
   "source": [
    "def item_based_recommend(user_id: str, \n",
    "                          user_item_time_dict: dict, \n",
    "                          i2i_sim: dict, \n",
    "                          sim_item_topk: int, \n",
    "                          recall_item_num: int, \n",
    "                          item_topk_click: list) -> dict:\n",
    "    \"\"\"\n",
    "    基于文章协同过滤的召回。\n",
    "\n",
    "    Args:\n",
    "        user_id (`str`): 用户 ID。\n",
    "        user_item_time_dict (`dict`): 字典，记录用户的点击文章序列，格式为 {user1: {item1: time1, item2: time2, ...} ...}。\n",
    "        i2i_sim (`dict`): 字典，文章相似性矩阵。\n",
    "        sim_item_topk (`int`): 整数，选择与当前文章最相似的前 k 篇文章。\n",
    "        recall_item_num (`int`): 整数，最后召回的文章数量。\n",
    "        item_topk_click (`list`): 列表，点击次数最多的文章列表，用于用户召回补全。\n",
    "\n",
    "    Returns:\n",
    "        `dict`: 召回的文章列表，格式为 {item1: score1, item2: score2, ...}。\n",
    "\n",
    "    注意:\n",
    "        基于物品的协同过滤（详细请参考上一期推荐系统基础的组队学习），\n",
    "        在多路召回部分会加上关联规则的召回策略。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 获取用户历史交互的文章\n",
    "    user_hist_items = user_item_time_dict[user_id]\n",
    "    \n",
    "    item_rank = {}\n",
    "    for loc, (i, click_time) in enumerate(user_hist_items.items()):\n",
    "        # 对于用户历史文章 i，获取与之相似的文章 j\n",
    "        for j, wij in sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)[:sim_item_topk]:\n",
    "            if j in user_hist_items:\n",
    "                continue  # 跳过用户已点击的文章\n",
    "            \n",
    "            # 更新文章 j 的得分\n",
    "            item_rank[j] = item_rank.get(j, 0) + wij\n",
    "    \n",
    "    # 如果不足 recall_item_num 个，用热门商品补全\n",
    "    if len(item_rank) < recall_item_num:\n",
    "        for i, item in enumerate(item_topk_click):\n",
    "            if item in item_rank:  # 填充的 item 应该不在原来的列表中\n",
    "                continue\n",
    "            item_rank[item] = -i - 100  # 随便给个负数就行\n",
    "            if len(item_rank) == recall_item_num:\n",
    "                break\n",
    "    \n",
    "    # 根据得分排序并返回前 recall_item_num 个文章\n",
    "    item_rank = sorted(item_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]\n",
    "    return item_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe45b267616c795",
   "metadata": {},
   "source": [
    "## 给每个用户根据物品的 ItemCF 推荐文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "985e5f142bb4fc16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:51:18.205985Z",
     "start_time": "2024-11-18T07:55:12.663804Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [55:49<00:00, 74.65it/s]  \n"
     ]
    }
   ],
   "source": [
    "user_recall_items_dict = defaultdict(dict)\n",
    "\n",
    "# 获取【用户-文章-点击时间】的字典\n",
    "user_item_time_dict = get_user_item_time(all_click_df)\n",
    "\n",
    "# 获取文章相似度\n",
    "i2i_sim = pickle.load(open('../tmp_results/itemcf_i2i_sim.pkl', 'rb'))\n",
    "\n",
    "# 相似文章的数量\n",
    "sim_item_topk = 10\n",
    "\n",
    "# 召回文章的数量\n",
    "recall_item_num = 10\n",
    "\n",
    "# 得到点击次数最多的物品\n",
    "item_topk_click = get_item_topk_click(all_click_df, k=50)\n",
    "\n",
    "for user in tqdm(all_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa1a95882f82c7",
   "metadata": {},
   "source": [
    "## 召回字典转换成 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2b76ed59c163158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T09:08:34.422803Z",
     "start_time": "2024-11-18T09:08:20.629866Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [00:04<00:00, 54033.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199999</td>\n",
       "      <td>276970</td>\n",
       "      <td>0.172377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199999</td>\n",
       "      <td>158536</td>\n",
       "      <td>0.106969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199999</td>\n",
       "      <td>168623</td>\n",
       "      <td>0.103572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199999</td>\n",
       "      <td>123909</td>\n",
       "      <td>0.103572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199999</td>\n",
       "      <td>286321</td>\n",
       "      <td>0.097774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499995</th>\n",
       "      <td>200000</td>\n",
       "      <td>187005</td>\n",
       "      <td>0.071191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499996</th>\n",
       "      <td>200000</td>\n",
       "      <td>50573</td>\n",
       "      <td>0.071180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499997</th>\n",
       "      <td>200000</td>\n",
       "      <td>63344</td>\n",
       "      <td>0.071180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499998</th>\n",
       "      <td>200000</td>\n",
       "      <td>255153</td>\n",
       "      <td>0.068034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499999</th>\n",
       "      <td>200000</td>\n",
       "      <td>195603</td>\n",
       "      <td>0.065900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id  pred_score\n",
       "0         199999            276970    0.172377\n",
       "1         199999            158536    0.106969\n",
       "2         199999            168623    0.103572\n",
       "3         199999            123909    0.103572\n",
       "4         199999            286321    0.097774\n",
       "...          ...               ...         ...\n",
       "2499995   200000            187005    0.071191\n",
       "2499996   200000             50573    0.071180\n",
       "2499997   200000             63344    0.071180\n",
       "2499998   200000            255153    0.068034\n",
       "2499999   200000            195603    0.065900\n",
       "\n",
       "[2500000 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将字典的形式转换成 df\n",
    "user_item_score_list = []\n",
    "\n",
    "for user, items in tqdm(user_recall_items_dict.items()):\n",
    "    for item, score in items:\n",
    "        user_item_score_list.append([user, item, score])\n",
    "\n",
    "recall_df = pd.DataFrame(user_item_score_list, columns=['user_id', 'click_article_id', 'pred_score'])\n",
    "recall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "252b9d4cab0a9b61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T09:20:53.421913Z",
     "start_time": "2024-11-18T09:20:53.407725Z"
    }
   },
   "outputs": [],
   "source": [
    "# 生成提交文件\n",
    "def submit(recall_df: pd.DataFrame, topk: int = 5, model_name: str = None) -> None:\n",
    "    \"\"\"\n",
    "    生成提交文件，将推荐结果格式化并保存为 CSV 文件。\n",
    "\n",
    "    Args:\n",
    "        recall_df (`pd.DataFrame`): 包含用户推荐结果的 DataFrame，必须包含 'user_id' 和 'pred_score' 列。\n",
    "        topk (`int`): 每个用户需要提交的推荐文章数量，默认为 5。\n",
    "        model_name (`str`): 模型名称，用于生成文件名。\n",
    "\n",
    "    Returns:\n",
    "        None: 该函数不返回值，而是将结果保存为 CSV 文件。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 根据用户 ID 和预测分数排序\n",
    "    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'])\n",
    "    \n",
    "    # 为每个用户的预测分数排名\n",
    "    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 检查每个用户是否都有至少 topk 篇文章\n",
    "    tmp = recall_df.groupby('user_id').apply(lambda x: x['rank'].max())\n",
    "    assert tmp.min() >= topk  # 确保每个用户的最大排名大于等于 topk\n",
    "    \n",
    "    # 删除预测分数列\n",
    "    del recall_df['pred_score']\n",
    "    \n",
    "    # 选择排名前 topk 的文章，并重塑 DataFrame 结构\n",
    "    submit = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n",
    "    submit.columns = [int(col) if isinstance(col, int) else col for col in submit.columns.droplevel(0)]\n",
    "    \n",
    "    # 按照提交格式定义列名\n",
    "    submit = submit.rename(columns={'': 'user_id',\n",
    "                                     '1': 'article_1',\n",
    "                                     '2': 'article_2',\n",
    "                                     '3': 'article_3',\n",
    "                                     '4': 'article_4',\n",
    "                                     '5': 'article_5'})\n",
    "    \n",
    "    # 生成保存文件的名称\n",
    "    save_name = model_name + '_' + datetime.today().strftime('%m-%d') + '.csv'\n",
    "    \n",
    "    # 保存结果为 CSV 文件\n",
    "    submit.to_csv(save_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76e4fc708d65db97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T09:28:30.254276Z",
     "start_time": "2024-11-18T09:28:24.039598Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取测试集\n",
    "tst_click = pd.read_csv('../data/testA_click_log.csv')\n",
    "tst_users = tst_click['user_id'].unique()\n",
    "\n",
    "# 从所有召回数据中将测试集中的用户选出来\n",
    "tst_recall = recall_df[recall_df['user_id'].isin(tst_users)]\n",
    "\n",
    "# 生成提交文件\n",
    "submit(tst_recall, topk=5, model_name='itemcf_baseline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
