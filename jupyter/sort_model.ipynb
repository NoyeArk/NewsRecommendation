{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 排序模型\n",
    "\n",
    "通过召回的操作，我们已经进行了问题规模的缩减，对于每个用户，选择出了 N 篇文章作为了候选集，并基于召回的候选集构建了与用户历史相关的特征，以及用户本身的属性特征，文章本身的属性特征，以及用户与文章之间的特征。\n",
    "\n",
    "下面就是使用机器学习模型来对构造好的特征进行学习，然后对测试集进行预测，得到测试集中的每个候选集用户点击的概率，返回点击概率最大的 topk 个文章，作为最终的结果。\n",
    "\n",
    "排序阶段选择了三个比较有代表性的排序模型，它们分别是：\n",
    "\n",
    "1. LGB 的排序模型\n",
    "2. LGB 的分类模型\n",
    "3. 深度学习的分类模型 DIN\n",
    "\n",
    "得到了最终的排序模型输出的结果之后，还选择了两种比较经典的模型集成的方法：\n",
    "\n",
    "1. 输出结果加权融合\n",
    "2. Staking（将模型的输出结果再使用一个简单模型进行预测）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 读取排序特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "save_path = '../tmp_results/'\n",
    "offline = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新读取数据的时候，发现 click_article_id 是一个浮点数，所以将其转换成int类型\n",
    "trn_user_item_feats_df = pd.read_csv(save_path + 'trn_user_item_feats_df.csv')\n",
    "trn_user_item_feats_df['click_article_id'] = trn_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df = pd.read_csv(save_path + 'val_user_item_feats_df.csv')\n",
    "    val_user_item_feats_df['click_article_id'] = val_user_item_feats_df['click_article_id'].astype(int)\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "    \n",
    "tst_user_item_feats_df = pd.read_csv(save_path + 'tst_user_item_feats_df.csv')\n",
    "tst_user_item_feats_df['click_article_id'] = tst_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "# 做特征的时候为了方便，给测试集也打上了一个无效的标签，这里直接删掉就行\n",
    "del tst_user_item_feats_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>sim0</th>\n",
       "      <th>time_diff0</th>\n",
       "      <th>word_diff0</th>\n",
       "      <th>sim_max</th>\n",
       "      <th>sim_min</th>\n",
       "      <th>sim_sum</th>\n",
       "      <th>sim_mean</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>user_time_hob1</th>\n",
       "      <th>user_time_hob2</th>\n",
       "      <th>words_hbo</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "      <th>is_cat_hab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36162</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>7920000</td>\n",
       "      <td>43</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.838929</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>43</td>\n",
       "      <td>1508177171000</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3244</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>34968000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>1.288687</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1508220059000</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>63746</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>37324000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.659610</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.343618</td>\n",
       "      <td>0.992721</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>133</td>\n",
       "      <td>1508142585000</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>63795</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>897477000</td>\n",
       "      <td>52</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.439456</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.343618</td>\n",
       "      <td>0.992721</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>133</td>\n",
       "      <td>1507282432000</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>168564</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>169421000</td>\n",
       "      <td>71</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.617176</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343651</td>\n",
       "      <td>0.992020</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>297</td>\n",
       "      <td>1508007750000</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291030</th>\n",
       "      <td>199997</td>\n",
       "      <td>225499</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>377348000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>2.027832</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019385</td>\n",
       "      <td>0.989068</td>\n",
       "      <td>174.500000</td>\n",
       "      <td>354</td>\n",
       "      <td>1506636615000</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291031</th>\n",
       "      <td>199998</td>\n",
       "      <td>236648</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>31230000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.946671</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.152570</td>\n",
       "      <td>0.990487</td>\n",
       "      <td>189.475000</td>\n",
       "      <td>375</td>\n",
       "      <td>1508104674000</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291032</th>\n",
       "      <td>199998</td>\n",
       "      <td>260604</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>411590000</td>\n",
       "      <td>53</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>0.957341</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.152570</td>\n",
       "      <td>0.990487</td>\n",
       "      <td>189.475000</td>\n",
       "      <td>395</td>\n",
       "      <td>1507661854000</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291033</th>\n",
       "      <td>199999</td>\n",
       "      <td>218355</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>259000</td>\n",
       "      <td>111</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.742256</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152674</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>200.272727</td>\n",
       "      <td>352</td>\n",
       "      <td>1508155745000</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291034</th>\n",
       "      <td>199999</td>\n",
       "      <td>158794</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>497317000</td>\n",
       "      <td>125</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>0.910821</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152674</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>200.272727</td>\n",
       "      <td>281</td>\n",
       "      <td>1507658687000</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291035 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  click_article_id      sim0  time_diff0  word_diff0   sim_max  \\\n",
       "0             0             36162  0.031281     7920000          43  0.031281   \n",
       "1             0              3244  0.163423    34968000           9  0.163423   \n",
       "2             1             63746  0.060468    37324000          14  0.060468   \n",
       "3             1             63795  0.105641   897477000          52  0.105641   \n",
       "4             2            168564  0.619400   169421000          71  0.619400   \n",
       "...         ...               ...       ...         ...         ...       ...   \n",
       "291030   199997            225499  0.825229   377348000          25  0.825229   \n",
       "291031   199998            236648  0.137503    31230000          11  0.137503   \n",
       "291032   199998            260604 -0.009700   411590000          53 -0.009700   \n",
       "291033   199999            218355  0.155957      259000         111  0.155957   \n",
       "291034   199999            158794  0.585585   497317000         125  0.585585   \n",
       "\n",
       "         sim_min   sim_sum  sim_mean     score  ...  click_country  \\\n",
       "0       0.031281  0.031281  0.031281  0.838929  ...              1   \n",
       "1       0.163423  0.163423  0.163423  1.288687  ...              1   \n",
       "2       0.060468  0.060468  0.060468  0.659610  ...              1   \n",
       "3       0.105641  0.105641  0.105641  0.439456  ...              1   \n",
       "4       0.619400  0.619400  0.619400  0.617176  ...              1   \n",
       "...          ...       ...       ...       ...  ...            ...   \n",
       "291030  0.825229  0.825229  0.825229  2.027832  ...              1   \n",
       "291031  0.137503  0.137503  0.137503  0.946671  ...              1   \n",
       "291032 -0.009700 -0.009700 -0.009700  0.957341  ...              1   \n",
       "291033  0.155957  0.155957  0.155957  0.742256  ...              1   \n",
       "291034  0.585585  0.585585  0.585585  0.910821  ...              1   \n",
       "\n",
       "        click_region  click_referrer_type  user_time_hob1  user_time_hob2  \\\n",
       "0                 25                    2        0.343715        0.992865   \n",
       "1                 25                    2        0.343715        0.992865   \n",
       "2                 25                    6        0.343618        0.992721   \n",
       "3                 25                    6        0.343618        0.992721   \n",
       "4                 25                    2        0.343651        0.992020   \n",
       "...              ...                  ...             ...             ...   \n",
       "291030            16                    1        0.019385        0.989068   \n",
       "291031            25                    5        0.152570        0.990487   \n",
       "291032            25                    5        0.152570        0.990487   \n",
       "291033            13                    1        0.152674        0.990746   \n",
       "291034            13                    1        0.152674        0.990746   \n",
       "\n",
       "         words_hbo  category_id  created_at_ts  words_count  is_cat_hab  \n",
       "0       266.000000           43  1508177171000          205           0  \n",
       "1       266.000000            1  1508220059000          153           0  \n",
       "2       169.000000          133  1508142585000          162           0  \n",
       "3       169.000000          133  1507282432000          228           0  \n",
       "4       210.000000          297  1508007750000          276           0  \n",
       "...            ...          ...            ...          ...         ...  \n",
       "291030  174.500000          354  1506636615000          181           0  \n",
       "291031  189.475000          375  1508104674000          184           0  \n",
       "291032  189.475000          395  1507661854000          226           0  \n",
       "291033  200.272727          352  1508155745000          202           0  \n",
       "291034  200.272727          281  1507658687000          216           0  \n",
       "\n",
       "[291035 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2 返回排序后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(recall_df: pd.DataFrame, topk: int = 5, model_name: str = None) -> None:\n",
    "    \"\"\"\n",
    "    提交推荐结果，生成提交格式的 DataFrame 并保存为 CSV 文件。\n",
    "\n",
    "    Args:\n",
    "        recall_df (`pd.DataFrame`): 包含用户推荐结果的 DataFrame，必须包含 'user_id' 和 'pred_score' 列。\n",
    "        topk (`int`, optional): 每个用户推荐的文章数量，默认为 5。\n",
    "        model_name (`str`, optional): 模型名称，用于保存文件时的命名。\n",
    "\n",
    "    Returns:\n",
    "        `None`: 该函数没有返回值，但会将结果保存为 CSV 文件。\n",
    "    \"\"\"\n",
    "    # 根据用户 ID 和预测分数排序\n",
    "    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'], ascending=[True, False])\n",
    "    \n",
    "    # 为每个用户的推荐结果打排名\n",
    "    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 检查每个用户至少有 topk 篇文章\n",
    "    tmp = recall_df.groupby('user_id').apply(lambda x: x['rank'].max())\n",
    "    assert tmp.min() >= topk, f\"Some users do not have at least {topk} articles.\"\n",
    "    \n",
    "    # 删除预测分数列\n",
    "    del recall_df['pred_score']\n",
    "    \n",
    "    # 选择排名在 topk 以内的文章并调整 DataFrame 格式\n",
    "    submit = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n",
    "    \n",
    "    # 转换列名，去掉多层索引\n",
    "    submit.columns = [int(col) if isinstance(col, int) else col for col in submit.columns.droplevel(0)]\n",
    "    \n",
    "    # 按照提交格式定义列名\n",
    "    submit = submit.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2', \n",
    "                                     3: 'article_3', 4: 'article_4', 5: 'article_5'})\n",
    "    \n",
    "    # 保存结果为 CSV 文件\n",
    "    save_name = save_path + model_name + '_' + datetime.today().strftime('%m-%d') + '.csv'\n",
    "    submit.to_csv(save_name, index=False, header=True)  # 保存不包含索引，包含标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_sim(sim_df: pd.Series, weight: float = 0.0) -> pd.Series:\n",
    "    \"\"\"\n",
    "    对相似度得分进行归一化处理。\n",
    "\n",
    "    Args:\n",
    "        sim_df (`pd.Series`): 输入的相似度得分 Series。\n",
    "        weight (`float`, optional): 归一化后加上的权重，默认为 0.0。\n",
    "\n",
    "    Returns:\n",
    "        `pd.Series`: 归一化后的相似度得分 Series。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 获取相似度得分的最小值和最大值\n",
    "    min_sim = sim_df.min()\n",
    "    max_sim = sim_df.max()\n",
    "    \n",
    "    # 如果最大值等于最小值，则所有得分都设置为 1.0\n",
    "    if max_sim == min_sim:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0)\n",
    "    else:\n",
    "        # 否则进行线性归一化处理\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0 * (sim - min_sim) / (max_sim - min_sim))\n",
    "\n",
    "    # 将指定的权重加到归一化后的相似度得分上\n",
    "    sim_df = sim_df.apply(lambda sim: sim + weight)  # 加上权重\n",
    "\n",
    "    return sim_df  # 返回归一化后的相似度得分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3 LGB 排序模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 防止中间出错之后重新读取数据\n",
    "trn_user_item_feats_df_rank_model = trn_user_item_feats_df.copy()\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_rank_model = val_user_item_feats_df.copy()\n",
    "    \n",
    "tst_user_item_feats_df_rank_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义特征列\n",
    "lgb_cols = ['sim0', 'time_diff0', 'word_diff0','sim_max', 'sim_min', 'sim_sum', \n",
    "            'sim_mean', 'score','click_size', 'time_diff_mean', 'active_level',\n",
    "            'click_environment','click_deviceGroup', 'click_os', 'click_country', \n",
    "            'click_region','click_referrer_type', 'user_time_hob1', 'user_time_hob2',\n",
    "            'words_hbo', 'category_id', 'created_at_ts','words_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序模型分组\n",
    "trn_user_item_feats_df_rank_model.sort_values(by=['user_id'], inplace=True)\n",
    "g_train = trn_user_item_feats_df_rank_model.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_rank_model.sort_values(by=['user_id'], inplace=True)\n",
    "    g_val = val_user_item_feats_df_rank_model.groupby(['user_id'], as_index=False).count()[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序模型定义\n",
    "lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>sim0</th>\n",
       "      <th>time_diff0</th>\n",
       "      <th>word_diff0</th>\n",
       "      <th>sim_max</th>\n",
       "      <th>sim_min</th>\n",
       "      <th>sim_sum</th>\n",
       "      <th>sim_mean</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>user_time_hob1</th>\n",
       "      <th>user_time_hob2</th>\n",
       "      <th>words_hbo</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "      <th>is_cat_hab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36162</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>7920000</td>\n",
       "      <td>43</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.838929</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>43</td>\n",
       "      <td>1508177171000</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3244</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>34968000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>1.288687</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1508220059000</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>63746</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>37324000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.659610</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.343618</td>\n",
       "      <td>0.992721</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>133</td>\n",
       "      <td>1508142585000</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>63795</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>897477000</td>\n",
       "      <td>52</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.439456</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.343618</td>\n",
       "      <td>0.992721</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>133</td>\n",
       "      <td>1507282432000</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>168564</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>169421000</td>\n",
       "      <td>71</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.617176</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343651</td>\n",
       "      <td>0.992020</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>297</td>\n",
       "      <td>1508007750000</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291030</th>\n",
       "      <td>199997</td>\n",
       "      <td>225499</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>377348000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>2.027832</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019385</td>\n",
       "      <td>0.989068</td>\n",
       "      <td>174.500000</td>\n",
       "      <td>354</td>\n",
       "      <td>1506636615000</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291031</th>\n",
       "      <td>199998</td>\n",
       "      <td>236648</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>31230000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.946671</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.152570</td>\n",
       "      <td>0.990487</td>\n",
       "      <td>189.475000</td>\n",
       "      <td>375</td>\n",
       "      <td>1508104674000</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291032</th>\n",
       "      <td>199998</td>\n",
       "      <td>260604</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>411590000</td>\n",
       "      <td>53</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>0.957341</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.152570</td>\n",
       "      <td>0.990487</td>\n",
       "      <td>189.475000</td>\n",
       "      <td>395</td>\n",
       "      <td>1507661854000</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291033</th>\n",
       "      <td>199999</td>\n",
       "      <td>218355</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>259000</td>\n",
       "      <td>111</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.742256</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152674</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>200.272727</td>\n",
       "      <td>352</td>\n",
       "      <td>1508155745000</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291034</th>\n",
       "      <td>199999</td>\n",
       "      <td>158794</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>497317000</td>\n",
       "      <td>125</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>0.910821</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152674</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>200.272727</td>\n",
       "      <td>281</td>\n",
       "      <td>1507658687000</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291035 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  click_article_id      sim0  time_diff0  word_diff0   sim_max  \\\n",
       "0             0             36162  0.031281     7920000          43  0.031281   \n",
       "1             0              3244  0.163423    34968000           9  0.163423   \n",
       "2             1             63746  0.060468    37324000          14  0.060468   \n",
       "3             1             63795  0.105641   897477000          52  0.105641   \n",
       "4             2            168564  0.619400   169421000          71  0.619400   \n",
       "...         ...               ...       ...         ...         ...       ...   \n",
       "291030   199997            225499  0.825229   377348000          25  0.825229   \n",
       "291031   199998            236648  0.137503    31230000          11  0.137503   \n",
       "291032   199998            260604 -0.009700   411590000          53 -0.009700   \n",
       "291033   199999            218355  0.155957      259000         111  0.155957   \n",
       "291034   199999            158794  0.585585   497317000         125  0.585585   \n",
       "\n",
       "         sim_min   sim_sum  sim_mean     score  ...  click_country  \\\n",
       "0       0.031281  0.031281  0.031281  0.838929  ...              1   \n",
       "1       0.163423  0.163423  0.163423  1.288687  ...              1   \n",
       "2       0.060468  0.060468  0.060468  0.659610  ...              1   \n",
       "3       0.105641  0.105641  0.105641  0.439456  ...              1   \n",
       "4       0.619400  0.619400  0.619400  0.617176  ...              1   \n",
       "...          ...       ...       ...       ...  ...            ...   \n",
       "291030  0.825229  0.825229  0.825229  2.027832  ...              1   \n",
       "291031  0.137503  0.137503  0.137503  0.946671  ...              1   \n",
       "291032 -0.009700 -0.009700 -0.009700  0.957341  ...              1   \n",
       "291033  0.155957  0.155957  0.155957  0.742256  ...              1   \n",
       "291034  0.585585  0.585585  0.585585  0.910821  ...              1   \n",
       "\n",
       "        click_region  click_referrer_type  user_time_hob1  user_time_hob2  \\\n",
       "0                 25                    2        0.343715        0.992865   \n",
       "1                 25                    2        0.343715        0.992865   \n",
       "2                 25                    6        0.343618        0.992721   \n",
       "3                 25                    6        0.343618        0.992721   \n",
       "4                 25                    2        0.343651        0.992020   \n",
       "...              ...                  ...             ...             ...   \n",
       "291030            16                    1        0.019385        0.989068   \n",
       "291031            25                    5        0.152570        0.990487   \n",
       "291032            25                    5        0.152570        0.990487   \n",
       "291033            13                    1        0.152674        0.990746   \n",
       "291034            13                    1        0.152674        0.990746   \n",
       "\n",
       "         words_hbo  category_id  created_at_ts  words_count  is_cat_hab  \n",
       "0       266.000000           43  1508177171000          205           0  \n",
       "1       266.000000            1  1508220059000          153           0  \n",
       "2       169.000000          133  1508142585000          162           0  \n",
       "3       169.000000          133  1507282432000          228           0  \n",
       "4       210.000000          297  1508007750000          276           0  \n",
       "...            ...          ...            ...          ...         ...  \n",
       "291030  174.500000          354  1506636615000          181           0  \n",
       "291031  189.475000          375  1508104674000          184           0  \n",
       "291032  189.475000          395  1507661854000          226           0  \n",
       "291033  200.272727          352  1508155745000          202           0  \n",
       "291034  200.272727          281  1507658687000          216           0  \n",
       "\n",
       "[291035 rows x 28 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4124\n",
      "[LightGBM] [Info] Number of data points in the train set: 291035, number of used features: 23\n"
     ]
    }
   ],
   "source": [
    "# 排序模型训练\n",
    "if offline:\n",
    "    lgb_ranker.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'], group=g_train,\n",
    "                eval_set=[(val_user_item_feats_df_rank_model[lgb_cols], val_user_item_feats_df_rank_model['label'])], \n",
    "                eval_group= [g_val], eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ], early_stopping_rounds=50, )\n",
    "else:\n",
    "    lgb_ranker.fit(trn_user_item_feats_df[lgb_cols], trn_user_item_feats_df['label'], group=g_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "tst_user_item_feats_df['pred_score'] = lgb_ranker.predict(tst_user_item_feats_df[lgb_cols], num_iteration=lgb_ranker.best_iteration_)\n",
    "\n",
    "# 将这里的排序结果保存一份，用户后面的模型融合\n",
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_path + 'lgb_ranker_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_ranker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4133\n",
      "[LightGBM] [Info] Number of data points in the train set: 232954, number of used features: 23\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4131\n",
      "[LightGBM] [Info] Number of data points in the train set: 232735, number of used features: 23\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4133\n",
      "[LightGBM] [Info] Number of data points in the train set: 232931, number of used features: 23\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4130\n",
      "[LightGBM] [Info] Number of data points in the train set: 232855, number of used features: 23\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4130\n",
      "[LightGBM] [Info] Number of data points in the train set: 232665, number of used features: 23\n"
     ]
    }
   ],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    return user_set\n",
    "\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_rank_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id','label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 训练集与验证集的用户分组\n",
    "    train_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_train = train_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_val = valid_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    \n",
    "    # 定义模型\n",
    "    lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16)  \n",
    "    # 训练模型\n",
    "    lgb_ranker.fit(train_idx[lgb_cols], train_idx['label'], group=g_train,\n",
    "                   eval_set=[(valid_idx[lgb_cols], valid_idx['label'])], eval_group= [g_val], \n",
    "                   eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ])\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_ranker.predict(valid_idx[lgb_cols], num_iteration=lgb_ranker.best_iteration_)\n",
    "    \n",
    "    # 对输出结果进行归一化\n",
    "    valid_idx['pred_score'] = valid_idx[['pred_score']].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds += lgb_ranker.predict(tst_user_item_feats_df_rank_model[lgb_cols], lgb_ranker.best_iteration_)\n",
    "    \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_lgb_ranker_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均，将预测的 score 和对应的 rank 特征保存，可以用于后面的 staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = tst_user_item_feats_df_rank_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_lgb_ranker_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "# 单模型生成提交结果\n",
    "rank_results = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_ranker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4 LGB 分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型及参数的定义\n",
    "lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=500, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16, verbose=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 64190, number of negative: 226845\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.046175\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000006 seconds, init for row-wise cost 0.009883 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4125\n",
      "[LightGBM] [Info] Number of data points in the train set: 291035, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220558 -> initscore=-1.262420\n",
      "[LightGBM] [Info] Start training from score -1.262420\n",
      "[LightGBM] [Debug] Re-bagging, using 203724 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203329 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203611 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203557 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203650 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204159 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203601 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204061 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203895 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203751 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203496 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203919 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203959 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203735 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203414 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 204083 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203756 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203947 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203838 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 204049 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203353 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203544 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203452 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204313 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203752 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204185 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203771 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203427 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203292 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203906 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203802 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203487 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203815 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203591 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203607 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203751 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 203852 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203649 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203724 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203895 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 204149 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203745 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203687 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203676 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203852 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203685 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203500 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203128 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203576 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203790 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203488 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203295 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 204179 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203327 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203925 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203363 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203859 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203987 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203660 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204399 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203484 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203668 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203822 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203866 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203481 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203790 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203648 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203788 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203517 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203390 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203428 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203650 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203522 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203329 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203491 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203821 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203841 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203947 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203618 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203810 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 204222 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203550 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203657 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203736 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203749 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203356 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203940 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203723 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203021 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203985 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203876 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204033 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203790 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204165 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203796 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 204000 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203818 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203375 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203532 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203287 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203574 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203785 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203480 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203970 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203558 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203620 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203762 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203338 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204010 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203749 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203796 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203619 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203987 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203144 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203659 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203602 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 204183 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203531 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203678 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203908 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203754 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203822 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203492 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203747 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203453 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203936 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203438 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204073 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203675 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203788 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203814 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203555 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203554 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203374 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203936 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203658 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203668 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204003 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 204091 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203685 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203620 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203733 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203859 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203786 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203797 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203616 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203739 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203880 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203833 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203707 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203717 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203741 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203358 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203722 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203789 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203125 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203630 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203627 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203620 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203651 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204146 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203890 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203959 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203653 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 203515 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203695 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203601 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203792 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204034 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203575 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 204137 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203745 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203619 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203879 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203323 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204111 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203691 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203380 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203730 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203752 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203923 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203677 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203506 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203562 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203640 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204085 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204030 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203700 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203962 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204006 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203428 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203960 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203736 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203767 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203831 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204095 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203865 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203937 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203420 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203724 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204050 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203493 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203705 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203507 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203948 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203667 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203857 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203450 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203812 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203506 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203726 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203596 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203657 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203444 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203705 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203721 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 203531 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204198 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204190 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203826 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 202997 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203925 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203449 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203996 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203419 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203768 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 204047 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203348 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204147 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204234 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204015 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203334 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203591 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203964 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203786 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203466 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203542 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203741 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203629 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203727 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203417 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203415 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203663 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203476 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203447 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203576 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204113 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203373 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203749 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203740 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204110 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204006 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204319 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204200 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203858 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203534 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204301 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203838 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203682 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203253 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204093 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203571 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203895 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203283 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204036 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203906 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203614 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203549 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203734 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203965 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203447 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203451 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203596 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203646 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203932 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203501 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203959 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203871 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203894 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203888 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203475 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203767 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203920 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203818 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203703 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203854 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203731 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203288 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203270 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203761 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203557 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203257 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203744 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203543 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203976 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203887 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203976 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203720 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203485 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203655 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204032 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203656 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203666 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203781 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203861 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203783 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203889 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204005 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204050 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204007 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203711 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203634 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204060 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203384 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203370 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204077 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Re-bagging, using 203841 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204072 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203776 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203797 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203599 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203958 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203649 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204073 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 204230 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203414 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203751 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204149 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203719 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203444 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203618 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203801 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203540 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203448 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203899 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203703 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203234 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203811 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203651 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 204085 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203837 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204075 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204006 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203538 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203842 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203540 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203823 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203588 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204000 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203359 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203929 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203566 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203805 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 21\n",
      "[LightGBM] [Debug] Re-bagging, using 203493 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203782 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203323 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203819 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203944 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203375 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203410 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203868 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 203785 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203614 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203806 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203821 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203768 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203866 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203681 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203622 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204234 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203855 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203497 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203439 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203810 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203520 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203279 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203983 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203248 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203574 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203821 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203466 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203631 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203734 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203984 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203763 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203589 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203913 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203737 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 204084 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203697 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 203668 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204093 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204124 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203716 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203679 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203287 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203937 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203876 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203956 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203614 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203636 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204023 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203699 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 20\n",
      "[LightGBM] [Debug] Re-bagging, using 203470 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203804 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203743 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203589 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203839 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203866 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203633 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 204021 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203879 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203584 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203553 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203715 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203446 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203406 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 204024 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203846 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203977 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203564 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203539 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203933 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203797 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203314 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203785 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203898 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203996 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203669 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203360 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
      "[LightGBM] [Debug] Re-bagging, using 204078 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203398 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203937 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203678 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203506 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203174 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203921 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 203479 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203675 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203548 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203410 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203433 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203948 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203816 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203616 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203735 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203302 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203665 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203665 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204007 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203514 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203735 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203244 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203858 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203398 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203580 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 204297 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203286 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203845 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204028 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203750 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203521 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203384 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 204035 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204109 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203502 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203866 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203597 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203870 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203358 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203332 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203544 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203386 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203447 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 203472 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 204244 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 203410 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203458 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203489 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203670 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203666 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203570 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203851 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 204143 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203867 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 203401 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203680 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203936 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 203332 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203696 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 203635 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203638 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 204115 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 203483 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204246 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Re-bagging, using 203108 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 203333 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203645 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 203512 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 204071 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "if offline:\n",
    "    lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'],\n",
    "                    eval_set=[(val_user_item_feats_df_rank_model[lgb_cols], val_user_item_feats_df_rank_model['label'])], \n",
    "                    eval_metric=['auc', ],early_stopping_rounds=50, )\n",
    "else:\n",
    "    lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "tst_user_item_feats_df['pred_score'] = lgb_Classfication.predict_proba(tst_user_item_feats_df[lgb_cols])[:,1]\n",
    "\n",
    "# 将这里的排序结果保存一份，用户后面的模型融合\n",
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_path + 'lgb_cls_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 51564, number of negative: 181390\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.046228\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000005 seconds, init for row-wise cost 0.007199 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4132\n",
      "[LightGBM] [Info] Number of data points in the train set: 232954, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221348 -> initscore=-1.257826\n",
      "[LightGBM] [Info] Start training from score -1.257826\n",
      "[LightGBM] [Debug] Re-bagging, using 163213 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162840 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162810 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162853 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162979 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163452 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162823 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163235 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 163220 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163057 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162795 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163249 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163344 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163135 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162880 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163432 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163159 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163284 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163077 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163209 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 162767 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162942 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162884 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163688 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163067 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163420 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163196 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162680 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162858 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163116 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163008 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162840 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163026 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162794 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162937 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163002 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163108 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162872 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163151 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163024 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 163590 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163073 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163098 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162998 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163349 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163014 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162963 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162637 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163158 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163034 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162827 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162690 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163258 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162851 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163235 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162906 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 163174 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163354 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162963 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163484 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162885 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163055 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163178 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163077 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 162762 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163018 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162925 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163215 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162764 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162832 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162686 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162884 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163004 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162815 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162931 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163161 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162978 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162985 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162822 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163071 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163506 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162907 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163014 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163004 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163095 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162764 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163285 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163040 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162403 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163215 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163356 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163282 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163023 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163343 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163058 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163189 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163048 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162741 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162820 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162763 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Info] Number of positive: 51261, number of negative: 181474\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.046176\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000004 seconds, init for row-wise cost 0.007381 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4132\n",
      "[LightGBM] [Info] Number of data points in the train set: 232735, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220255 -> initscore=-1.264182\n",
      "[LightGBM] [Info] Start training from score -1.264182\n",
      "[LightGBM] [Debug] Re-bagging, using 163053 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162691 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162661 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162697 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162845 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163301 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162678 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163085 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163035 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162906 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162644 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163076 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163172 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162989 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162724 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163282 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163007 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163117 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162928 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163056 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162619 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162772 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162731 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 163544 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162908 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163300 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163043 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162536 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Re-bagging, using 162717 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162964 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162884 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162689 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162857 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162654 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162793 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162848 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162951 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162747 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 163018 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162874 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163439 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162930 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162925 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162859 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163164 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162862 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162828 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162502 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162995 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162860 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162660 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162546 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163101 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162669 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163044 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162760 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163035 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163204 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162790 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163334 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162733 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162909 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163005 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162927 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162633 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162873 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162760 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163053 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162596 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162667 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162544 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162737 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162849 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162654 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162777 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163020 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162819 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162836 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162670 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162935 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163347 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162736 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162843 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162853 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162926 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162625 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163138 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162880 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162263 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163074 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163199 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163132 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162860 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163212 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162903 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163061 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162930 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162595 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162674 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162607 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Info] Number of positive: 51395, number of negative: 181536\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.046160\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000004 seconds, init for row-wise cost 0.007339 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4133\n",
      "[LightGBM] [Info] Number of data points in the train set: 232931, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220645 -> initscore=-1.261913\n",
      "[LightGBM] [Info] Start training from score -1.261913\n",
      "[LightGBM] [Debug] Re-bagging, using 163194 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162825 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162805 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162829 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162965 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163440 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162805 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163201 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163202 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163062 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162772 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163231 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163329 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163123 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162855 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163410 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163151 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163275 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163070 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163170 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162759 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162909 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162881 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163694 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163037 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163437 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163142 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162659 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162862 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163096 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163013 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162806 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162985 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162792 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162934 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162960 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 163104 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162861 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163151 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163003 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163564 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 163064 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163072 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162975 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163331 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163005 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162966 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162622 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163120 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163001 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162802 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162688 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163248 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162841 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 163192 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162903 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163180 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163340 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162931 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163458 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162896 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163039 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163137 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163054 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162776 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163031 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162901 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163165 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162734 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162817 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162686 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162882 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162990 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162802 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162900 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163146 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162959 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162969 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162825 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163062 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 163471 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162891 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162982 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162970 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163077 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162758 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163272 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163022 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162402 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163204 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163331 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163274 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162994 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163334 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163052 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163183 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163065 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162720 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162818 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162737 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Info] Number of positive: 51288, number of negative: 181567\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.046161\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000006 seconds, init for row-wise cost 0.007448 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4128\n",
      "[LightGBM] [Info] Number of data points in the train set: 232855, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220257 -> initscore=-1.264168\n",
      "[LightGBM] [Info] Start training from score -1.264168\n",
      "[LightGBM] [Debug] Re-bagging, using 163139 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162773 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162751 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162776 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162924 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163373 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162769 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163157 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163121 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162991 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162747 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163176 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 163254 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163073 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162814 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163356 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163081 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163211 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163031 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163138 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162705 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162855 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162796 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163636 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162999 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163382 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163139 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162610 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162796 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 163039 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162969 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 162754 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162939 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162752 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162871 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162908 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 163051 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162780 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163092 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162952 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163537 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163008 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163005 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162948 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163275 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162953 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162905 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162562 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163070 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162945 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162755 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162608 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163186 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162776 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163142 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162852 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163111 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163263 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162883 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163408 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162846 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162985 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163091 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163021 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162721 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162957 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162845 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163165 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162695 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162754 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162617 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162827 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162939 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162752 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162864 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163077 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162912 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162931 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162762 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163005 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163418 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162825 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162941 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162937 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163020 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162704 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163214 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162961 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162330 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 163151 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163274 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163216 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162947 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163295 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162995 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163110 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163007 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162678 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162758 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162679 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Info] Number of positive: 51252, number of negative: 181413\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.046197\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000004 seconds, init for row-wise cost 0.007817 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4129\n",
      "[LightGBM] [Info] Number of data points in the train set: 232665, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220282 -> initscore=-1.264022\n",
      "[LightGBM] [Info] Start training from score -1.264022\n",
      "[LightGBM] [Debug] Re-bagging, using 163000 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162641 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162614 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162651 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162794 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163254 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162624 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163048 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162994 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162856 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162592 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 163030 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163139 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162928 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162667 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163209 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162942 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163073 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162904 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162995 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 162577 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162731 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162670 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163483 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162859 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163251 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163005 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162476 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 162662 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162922 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162832 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 162643 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162810 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162605 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162745 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162795 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162916 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162680 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162971 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162836 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163381 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162886 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Re-bagging, using 162875 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162802 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163144 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162824 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162779 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162436 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162955 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162832 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162622 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162483 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163066 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162646 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163002 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 162704 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162977 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163158 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162733 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163273 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162687 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162848 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162966 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162890 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162575 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162825 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162716 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163012 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162551 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162621 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162480 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Re-bagging, using 162688 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162784 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162615 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162725 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162964 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162790 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162781 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162616 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162881 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163297 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162708 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162802 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162803 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 162880 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162570 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 163072 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162832 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162197 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 163023 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 163134 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 163085 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162807 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 163158 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162857 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 162998 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 162871 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162531 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 162622 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 162577 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n"
     ]
    }
   ],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    return user_set\n",
    "\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_rank_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id', 'label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 模型及参数的定义\n",
    "    lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16, verbose=10)  \n",
    "    # 训练模型\n",
    "    lgb_Classfication.fit(train_idx[lgb_cols], train_idx['label'],eval_set=[(valid_idx[lgb_cols], valid_idx['label'])], \n",
    "                          eval_metric=['auc', ])\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_Classfication.predict_proba(valid_idx[lgb_cols], \n",
    "                                                              num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    \n",
    "    # 对输出结果进行归一化 分类模型输出的值本身就是一个概率值不需要进行归一化\n",
    "    # valid_idx['pred_score'] = valid_idx[['pred_score']].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds += lgb_Classfication.predict_proba(tst_user_item_feats_df_rank_model[lgb_cols], \n",
    "                                                     num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_lgb_cls_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均，将预测的 score 和对应的 rank 特征保存，可以用于后面的 staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = tst_user_item_feats_df_rank_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_lgb_cls_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5 DIN 模型\n",
    "\n",
    "### 5.1 用户的历史点击行为列表\n",
    "\n",
    "这个是为后面的DIN模型服务的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if offline:\n",
    "    all_data = pd.read_csv('../data/train_click_log.csv')\n",
    "else:\n",
    "    trn_data = pd.read_csv('../data/train_click_log.csv')\n",
    "    tst_data = pd.read_csv('../data/testA_click_log.csv')\n",
    "    all_data = pd.concat([trn_data, tst_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_click = all_data[['user_id', 'click_article_id']].groupby('user_id').agg({list}).reset_index()\n",
    "his_behavior_df = pd.DataFrame()\n",
    "his_behavior_df['user_id'] = hist_click['user_id']\n",
    "his_behavior_df['hist_click_article_id'] = hist_click['click_article_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_user_item_feats_df_din_model = trn_user_item_feats_df.copy()\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_din_model = val_user_item_feats_df.copy()\n",
    "else: \n",
    "    val_user_item_feats_df_din_model = None\n",
    "    \n",
    "tst_user_item_feats_df_din_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_user_item_feats_df_din_model = trn_user_item_feats_df_din_model.merge(his_behavior_df, on='user_id')\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_din_model = val_user_item_feats_df_din_model.merge(his_behavior_df, on='user_id')\n",
    "else:\n",
    "    val_user_item_feats_df_din_model = None\n",
    "\n",
    "tst_user_item_feats_df_din_model = tst_user_item_feats_df_din_model.merge(his_behavior_df, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>sim0</th>\n",
       "      <th>time_diff0</th>\n",
       "      <th>word_diff0</th>\n",
       "      <th>sim_max</th>\n",
       "      <th>sim_min</th>\n",
       "      <th>sim_sum</th>\n",
       "      <th>sim_mean</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>user_time_hob1</th>\n",
       "      <th>user_time_hob2</th>\n",
       "      <th>words_hbo</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "      <th>is_cat_hab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36162</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>7920000</td>\n",
       "      <td>43</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.838929</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>43</td>\n",
       "      <td>1508177171000</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3244</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>34968000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>1.288687</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1508220059000</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>63746</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>37324000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.659610</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.343618</td>\n",
       "      <td>0.992721</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>133</td>\n",
       "      <td>1508142585000</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>63795</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>897477000</td>\n",
       "      <td>52</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.439456</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.343618</td>\n",
       "      <td>0.992721</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>133</td>\n",
       "      <td>1507282432000</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>168564</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>169421000</td>\n",
       "      <td>71</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.617176</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343651</td>\n",
       "      <td>0.992020</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>297</td>\n",
       "      <td>1508007750000</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291030</th>\n",
       "      <td>199997</td>\n",
       "      <td>225499</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>377348000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>2.027832</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019385</td>\n",
       "      <td>0.989068</td>\n",
       "      <td>174.500000</td>\n",
       "      <td>354</td>\n",
       "      <td>1506636615000</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291031</th>\n",
       "      <td>199998</td>\n",
       "      <td>236648</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>31230000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.946671</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.152570</td>\n",
       "      <td>0.990487</td>\n",
       "      <td>189.475000</td>\n",
       "      <td>375</td>\n",
       "      <td>1508104674000</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291032</th>\n",
       "      <td>199998</td>\n",
       "      <td>260604</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>411590000</td>\n",
       "      <td>53</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>-0.009700</td>\n",
       "      <td>0.957341</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.152570</td>\n",
       "      <td>0.990487</td>\n",
       "      <td>189.475000</td>\n",
       "      <td>395</td>\n",
       "      <td>1507661854000</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291033</th>\n",
       "      <td>199999</td>\n",
       "      <td>218355</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>259000</td>\n",
       "      <td>111</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.742256</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152674</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>200.272727</td>\n",
       "      <td>352</td>\n",
       "      <td>1508155745000</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291034</th>\n",
       "      <td>199999</td>\n",
       "      <td>158794</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>497317000</td>\n",
       "      <td>125</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>0.585585</td>\n",
       "      <td>0.910821</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152674</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>200.272727</td>\n",
       "      <td>281</td>\n",
       "      <td>1507658687000</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291035 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  click_article_id      sim0  time_diff0  word_diff0   sim_max  \\\n",
       "0             0             36162  0.031281     7920000          43  0.031281   \n",
       "1             0              3244  0.163423    34968000           9  0.163423   \n",
       "2             1             63746  0.060468    37324000          14  0.060468   \n",
       "3             1             63795  0.105641   897477000          52  0.105641   \n",
       "4             2            168564  0.619400   169421000          71  0.619400   \n",
       "...         ...               ...       ...         ...         ...       ...   \n",
       "291030   199997            225499  0.825229   377348000          25  0.825229   \n",
       "291031   199998            236648  0.137503    31230000          11  0.137503   \n",
       "291032   199998            260604 -0.009700   411590000          53 -0.009700   \n",
       "291033   199999            218355  0.155957      259000         111  0.155957   \n",
       "291034   199999            158794  0.585585   497317000         125  0.585585   \n",
       "\n",
       "         sim_min   sim_sum  sim_mean     score  ...  click_country  \\\n",
       "0       0.031281  0.031281  0.031281  0.838929  ...              1   \n",
       "1       0.163423  0.163423  0.163423  1.288687  ...              1   \n",
       "2       0.060468  0.060468  0.060468  0.659610  ...              1   \n",
       "3       0.105641  0.105641  0.105641  0.439456  ...              1   \n",
       "4       0.619400  0.619400  0.619400  0.617176  ...              1   \n",
       "...          ...       ...       ...       ...  ...            ...   \n",
       "291030  0.825229  0.825229  0.825229  2.027832  ...              1   \n",
       "291031  0.137503  0.137503  0.137503  0.946671  ...              1   \n",
       "291032 -0.009700 -0.009700 -0.009700  0.957341  ...              1   \n",
       "291033  0.155957  0.155957  0.155957  0.742256  ...              1   \n",
       "291034  0.585585  0.585585  0.585585  0.910821  ...              1   \n",
       "\n",
       "        click_region  click_referrer_type  user_time_hob1  user_time_hob2  \\\n",
       "0                 25                    2        0.343715        0.992865   \n",
       "1                 25                    2        0.343715        0.992865   \n",
       "2                 25                    6        0.343618        0.992721   \n",
       "3                 25                    6        0.343618        0.992721   \n",
       "4                 25                    2        0.343651        0.992020   \n",
       "...              ...                  ...             ...             ...   \n",
       "291030            16                    1        0.019385        0.989068   \n",
       "291031            25                    5        0.152570        0.990487   \n",
       "291032            25                    5        0.152570        0.990487   \n",
       "291033            13                    1        0.152674        0.990746   \n",
       "291034            13                    1        0.152674        0.990746   \n",
       "\n",
       "         words_hbo  category_id  created_at_ts  words_count  is_cat_hab  \n",
       "0       266.000000           43  1508177171000          205           0  \n",
       "1       266.000000            1  1508220059000          153           0  \n",
       "2       169.000000          133  1508142585000          162           0  \n",
       "3       169.000000          133  1507282432000          228           0  \n",
       "4       210.000000          297  1508007750000          276           0  \n",
       "...            ...          ...            ...          ...         ...  \n",
       "291030  174.500000          354  1506636615000          181           0  \n",
       "291031  189.475000          375  1508104674000          184           0  \n",
       "291032  189.475000          395  1507661854000          226           0  \n",
       "291033  200.272727          352  1508155745000          202           0  \n",
       "291034  200.272727          281  1507658687000          216           0  \n",
       "\n",
       "[291035 rows x 28 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df_din_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 DIN 模型介绍\n",
    "\n",
    "我们下面尝试使用 DIN 模型，DIN 的全称是 Deep Interest Network，这是阿里 2018 年基于前面的深度学习模型无法表达用户多样化的兴趣而提出的一个模型，它可以通过考虑【给定的候选广告】和【用户的历史行为】的相关性，来计算用户兴趣的表示向量。\n",
    "\n",
    "具体来说就是通过<font color=red>引入局部激活单元，通过软搜索历史行为的相关部分来关注相关的用户兴趣，并采用加权和来获得有关候选广告的用户兴趣的表示</font>。与候选广告相关性较高的行为会获得较高的激活权重，并支配着用户兴趣。\n",
    "\n",
    "该表示向量在不同广告上有所不同，大大提高了模型的表达能力。所以该模型对于此次新闻推荐的任务也比较适合，我们在这里通过当前的候选文章与用户历史点击文章的相关性来计算用户对于文章的兴趣。\n",
    "\n",
    "该模型的结构如下：\n",
    "\n",
    "<img src=\"../image/din.png\">\n",
    "\n",
    "我们这里直接调包来使用这个模型，关于这个模型的详细细节部分我们会在下一期的推荐系统组队学习中给出。下面说一下该模型如何具体使用。\n",
    "\n",
    "deepctr 的函数原型如下：\n",
    "\n",
    "> def DIN(dnn_feature_columns, history_feature_list, dnn_use_bn=False, dnn_hidden_units=(200, 80), dnn_activation='relu', att_hidden_size=(80, 40), att_activation=\"dice\", att_weight_normalization=False, l2_reg_dnn=0, l2_reg_embedding=1e-6, dnn_dropout=0, seed=1024, task='binary'):\n",
    "\n",
    "- `dnn_feature_columns`：特征列，包含数据所有特征的列表\n",
    "- `history_feature_list`：用户历史行为列，反应用户历史行为的特征的列表\n",
    "- `dnn_use_bn`：是否使用 BatchNormalization\n",
    "- `dnn_hidden_units`：全连接层网络的层数和每一层神经元的个数， 一个列表或者元组\n",
    "- `dnn_activation_relu`：全连接网络的激活单元类型\n",
    "- `att_hidden_size`：注意力层的全连接网络的层数和每一层神经元的个数\n",
    "- `att_activation`：注意力层的激活单元类型\n",
    "- `att_weight_normalization`：是否归一化注意力得分\n",
    "- `l2_reg_dnn`：全连接网络的正则化系数\n",
    "- `l2_reg_embedding`：embedding向量的正则化稀疏\n",
    "- `dnn_dropout`：全连接网络的神经元的失活概率\n",
    "- `task`：任务，可以是分类，也可是是回归\n",
    "\n",
    "在具体使用的时候，我们必须要传入特征列和历史行为列，但是再传入之前，我们需要进行一下特征列的预处理。具体如下：\n",
    "\n",
    "首先，我们要处理数据集得到数据，由于我们是基于用户过去的行为去预测用户是否点击当前文章，所以我们需要把数据的特征列划分成数值型特征、离散型特征和历史行为特征列三部分，对于每一部分，DIN 模型的处理会有不同。\n",
    "\n",
    "#### 5.2.1 离散型特征\n",
    "\n",
    "在我们的数据集中就是那些类别型的特征，比如 user_id 这种，这种类别型特征，我们首先要经过 Embedding 处理得到每个特征的低维稠密型表示，既然要经过 Embedding，那么我们就需要为每一列的类别特征的取值建立一个字典，并指明 Embedding 维度，所以在使用 deepctr 的 DIN 模型准备数据的时候，我们需要通过 SparseFeat 函数指明这些类别型特征，这个函数的传入参数就是列名，列的唯一取值（建立字典用）和 Embedding 维度。\n",
    "\n",
    "#### 5.2.2 用户历史行为特征\n",
    "\n",
    "比如文章 id，文章的类别等这种，同样的我们需要先经过 Embedding 处理。只不过和上面不一样的地方是，对于这种特征，我们在得到每个特征的 Embedding 表示之后，还需要通过一个 Attention_layer 计算用户的历史行为和当前候选文章的相关性以此得到当前用户的 Embedding 向量。\n",
    "\n",
    "这个向量就可以基于当前的候选文章与用户过去点击过得历史文章的相似性的程度来反应用户的兴趣，并且随着用户的不同的历史点击来变化，去动态的模拟用户兴趣的变化过程。\n",
    "\n",
    "这类特征对于每个用户都是一个历史行为序列，对于每个用户，历史行为序列长度会不一样，可能有的用户点击的历史文章多，有的点击的历史文章少，所以我们还需要把这个长度统一起来。\n",
    "\n",
    "在为 DIN 模型准备数据的时候，我们首先要通过 SparseFeat 函数指明这些类别型特征，然后还需要通过 VarLenSparseFeat 函数再进行序列填充，使得每个用户的历史序列一样长，所以这个函数参数中会有个 maxlen，来指明序列的最大长度是多少。\n",
    "\n",
    "#### 5.2.3 连续型特征列\n",
    "\n",
    "对于连续型特征列，只需要用 DenseFeat 函数来指明列名和维度即可。\n",
    "\n",
    "处理完特征列之后，我们把相应的数据与列进行对应，就得到了最后的数据。\n",
    "\n",
    "下面根据具体的代码感受一下，逻辑是这样，首先我们需要写一个数据准备函数，在这里面就是根据上面的具体步骤准备数据，得到数据和特征列，然后就是建立 DIN 模型并训练，最后基于模型进行测试。\n",
    "\n",
    "---\n",
    "\n",
    "## 5.3 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入deepctr\n",
    "from deepctr.models import DIN\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat, get_feature_names\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import * \n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_din_feats_columns(df: pd.DataFrame, \n",
    "                          dense_fea: list, \n",
    "                          sparse_fea: list, \n",
    "                          behavior_fea: list, \n",
    "                          his_behavior_fea: list, \n",
    "                          emb_dim: int = 32, \n",
    "                          max_len: int = 100) -> tuple:\n",
    "    \"\"\"\n",
    "    数据准备函数，用于构建 Deep Interest Network (DIN) 的输入特征。\n",
    "\n",
    "    Args:\n",
    "        df (`pd.DataFrame`): 输入的数据集。\n",
    "        dense_fea (`list`): 数值型特征列的名称列表。\n",
    "        sparse_fea (`list`): 离散型特征列的名称列表。\n",
    "        behavior_fea (`list`): 用户的候选行为特征列名称列表。\n",
    "        his_behavior_fea (`list`): 用户的历史行为特征列名称列表。\n",
    "        emb_dim (`int`, optional): embedding 的维度，默认为 32。\n",
    "        max_len (`int`, optional): 用户序列的最大长度，默认为 100。\n",
    "\n",
    "    Returns:\n",
    "        `tuple`: 包含两个元素的元组：\n",
    "            - `x`: 特征字典，包含模型输入特征。\n",
    "            - `dnn_feature_columns`: DNN 特征列的列表。\n",
    "    \"\"\"\n",
    "    # 构建离散特征列，添加 vocabulary_size 和 embedding_dim\n",
    "    sparse_feature_columns = [SparseFeat(feat, vocabulary_size=df[feat].nunique() + 1, embedding_dim=emb_dim) for feat in sparse_fea]\n",
    "    \n",
    "    # 构建密集特征列\n",
    "    dense_feature_columns = [DenseFeat(feat, 1) for feat in dense_fea]\n",
    "    \n",
    "    # 构建变长离散特征列\n",
    "    var_feature_columns = [VarLenSparseFeat(SparseFeat(feat, vocabulary_size=df['click_article_id'].nunique() + 1,\n",
    "                                    embedding_dim=emb_dim, embedding_name='click_article_id'), maxlen=max_len) for feat in his_behavior_fea]\n",
    "    \n",
    "    # 合并所有特征列\n",
    "    dnn_feature_columns = sparse_feature_columns + dense_feature_columns + var_feature_columns\n",
    "    \n",
    "    # 初始化特征字典\n",
    "    x = {}\n",
    "    for name in get_feature_names(dnn_feature_columns):\n",
    "        if name in his_behavior_fea:\n",
    "            # 处理历史行为序列，进行填充以满足最大长度\n",
    "            his_list = [l for l in df[name]]\n",
    "            x[name] = pad_sequences(his_list, maxlen=max_len, padding='post')  # 生成二维数组\n",
    "        else:\n",
    "            x[name] = df[name].values  # 直接提取特征列的值\n",
    "    \n",
    "    return x, dnn_feature_columns  # 返回特征字典和特征列列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把特征分开\n",
    "sparse_fea = ['user_id', 'click_article_id', 'category_id', 'click_environment', 'click_deviceGroup', \n",
    "              'click_os', 'click_country', 'click_region', 'click_referrer_type', 'is_cat_hab']\n",
    "\n",
    "behavior_fea = ['click_article_id']\n",
    "\n",
    "hist_behavior_fea = ['hist_click_article_id']\n",
    "\n",
    "dense_fea = ['sim0', 'time_diff0', 'word_diff0', 'sim_max', 'sim_min', 'sim_sum', 'sim_mean', 'score',\n",
    "             'rank','click_size','time_diff_mean','active_level','user_time_hob1','user_time_hob2',\n",
    "             'words_hbo','words_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense特征进行归一化, 神经网络训练都需要将数值进行归一化处理\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "# 下面是做一些特殊处理，当在其他的地方出现无效值的时候，不处理无法进行归一化，刚开始可以先把他注释掉\n",
    "# 在运行了下面的代码之后如果发现报错，应该先去想办法处理如何不出现inf之类的值\n",
    "# trn_user_item_feats_df_din_model.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "# tst_user_item_feats_df_din_model.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "for feat in dense_fea:\n",
    "    trn_user_item_feats_df_din_model[feat] = mm.fit_transform(trn_user_item_feats_df_din_model[[feat]])\n",
    "    \n",
    "    if val_user_item_feats_df_din_model is not None:\n",
    "        val_user_item_feats_df_din_model[feat] = mm.fit_transform(val_user_item_feats_df_din_model[[feat]])\n",
    "    \n",
    "    tst_user_item_feats_df_din_model[feat] = mm.fit_transform(tst_user_item_feats_df_din_model[[feat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备训练数据\n",
    "x_trn, dnn_feature_columns = get_din_feats_columns(trn_user_item_feats_df_din_model, dense_fea, \n",
    "                                               sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "y_trn = trn_user_item_feats_df_din_model['label'].values\n",
    "\n",
    "if offline:\n",
    "    # 准备验证数据\n",
    "    x_val, dnn_feature_columns = get_din_feats_columns(val_user_item_feats_df_din_model, dense_fea, \n",
    "                                                   sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "    y_val = val_user_item_feats_df_din_model['label'].values\n",
    "    \n",
    "dense_fea = [x for x in dense_fea if x != 'label']\n",
    "x_tst, dnn_feature_columns = get_din_feats_columns(tst_user_item_feats_df_din_model, dense_fea, \n",
    "                                               sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_none(feature_columns: list) -> bool:\n",
    "    \"\"\"\n",
    "    检查特征列中是否存在 None 值。\n",
    "\n",
    "    Args:\n",
    "        feature_columns (`list`): 特征列的列表，可以包含不同类型的特征对象。\n",
    "\n",
    "    Returns:\n",
    "        `bool`: 如果发现 None 值，返回 True；否则返回 False。\n",
    "    \"\"\"\n",
    "    # 遍历所有特征\n",
    "    for feature in feature_columns:\n",
    "        if feature is None:\n",
    "            print(\"Found None in feature columns.\")\n",
    "            return True  # 发现 None 值，返回 True\n",
    "        \n",
    "        # 进一步检查特征的属性是否为 None\n",
    "        if isinstance(feature, SparseFeat):\n",
    "            if feature.name is None or feature.vocabulary_size is None or feature.embedding_dim is None:\n",
    "                print(f\"Found None in SparseFeat properties: {feature}\")\n",
    "                return True  # SparseFeat 属性中发现 None 值\n",
    "        elif isinstance(feature, DenseFeat):\n",
    "            if feature.name is None or feature.dimension is None:\n",
    "                print(f\"Found None in DenseFeat properties: {feature}\")\n",
    "                return True  # DenseFeat 属性中发现 None 值\n",
    "        elif isinstance(feature, VarLenSparseFeat):\n",
    "            if feature.sparsefeat is None or feature.maxlen is None:\n",
    "                print(f\"Found None in VarLenSparseFeat properties: {feature}\")\n",
    "                return True  # VarLenSparseFeat 属性中发现 None 值\n",
    "\n",
    "    print(\"No None values found in feature columns.\")\n",
    "    return False  # 没有发现 None 值，返回 False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No None values found in feature columns.\n"
     ]
    }
   ],
   "source": [
    "# 调用检查函数\n",
    "contains_none = check_for_none(dnn_feature_columns)  # 检查特征列中是否有 None 值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='user_id', vocabulary_size=50001, embedding_dim=32, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x000002CE901AB160>, embedding_name='user_id', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_article_id', vocabulary_size=16427, embedding_dim=32, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x000002CE901AAC50>, embedding_name='click_article_id', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='category_id', vocabulary_size=243, embedding_dim=32, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x000002CE901AAE30>, embedding_name='category_id', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_environment', vocabulary_size=4, embedding_dim=32, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x000002CE901AAAD0>, embedding_name='click_environment', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_deviceGroup', vocabulary_size=5, embedding_dim=32, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x000002CE901AA500>, embedding_name='click_deviceGroup', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_os', vocabulary_size=9, embedding_dim=32, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x000002CE901AAA70>, embedding_name='click_os', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_country', vocabulary_size=12, embedding_dim=32, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x000002CE901AA6B0>, embedding_name='click_country', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_region', vocabulary_size=29, embedding_dim=32, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x000002CE901AA5C0>, embedding_name='click_region', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_referrer_type', vocabulary_size=8, embedding_dim=32, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x000002CE901AA3E0>, embedding_name='click_referrer_type', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='is_cat_hab', vocabulary_size=2, embedding_dim=32, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x000002CE901AA2F0>, embedding_name='is_cat_hab', group_name='default_group', trainable=True),\n",
       " DenseFeat(name='sim0', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='time_diff0', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='word_diff0', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='sim_max', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='sim_min', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='sim_sum', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='sim_mean', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='score', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='rank', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='click_size', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='time_diff_mean', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='active_level', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='user_time_hob1', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='user_time_hob2', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='words_hbo', dimension=1, dtype='float32', transform_fn=None),\n",
       " DenseFeat(name='words_count', dimension=1, dtype='float32', transform_fn=None),\n",
       " VarLenSparseFeat(sparsefeat=SparseFeat(name='hist_click_article_id', vocabulary_size=16427, embedding_dim=32, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x000002CE901AA290>, embedding_name='click_article_id', group_name='default_group', trainable=True), maxlen=50, combiner='mean', length_name=None, weight_name=None, weight_norm=True)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "model = DIN(dnn_feature_columns, behavior_fea)\n",
    "\n",
    "# 查看模型结构\n",
    "print(model.summary())\n",
    "\n",
    "# 模型编译\n",
    "model.compile('adam', 'binary_crossentropy',metrics=['binary_crossentropy', tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'max'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax index in x_trn:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mx_trn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m())\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax index in y_trn:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_trn\u001b[38;5;241m.\u001b[39mmax())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'max'"
     ]
    }
   ],
   "source": [
    "print(\"Max index in x_trn:\", x_trn.max())\n",
    "print(\"Max index in y_trn:\", y_trn.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/sparse_seq_emb_hist_click_article_id/embedding_lookup_2' defined at (most recent call last):\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_15764\\3012139636.py\", line 7, in <module>\n      history = model.fit(x_trn, y_trn, verbose=1, epochs=2, batch_size=256)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1187, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 857, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 847, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 840, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 797, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1044, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 419, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 555, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1044, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\layers\\embeddings.py\", line 191, in call\n      out = embedding_ops.embedding_lookup_v2(self.embeddings, inputs)\nNode: 'model/sparse_seq_emb_hist_click_article_id/embedding_lookup_2'\nindices[0,0] = 183530 is not in [0, 16427)\n\t [[{{node model/sparse_seq_emb_hist_click_article_id/embedding_lookup_2}}]] [Op:__inference_train_function_4676]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m     history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_trn, y_trn, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(x_val, y_val) , batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# 也可以使用上面的语句用自己采样出来的验证集\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# history = model.fit(x_trn, y_trn, verbose=1, epochs=3, validation_split=0.3, batch_size=256)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1187\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1182\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1183\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1184\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1185\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1186\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1187\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1188\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1189\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model/sparse_seq_emb_hist_click_article_id/embedding_lookup_2' defined at (most recent call last):\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"f:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_15764\\3012139636.py\", line 7, in <module>\n      history = model.fit(x_trn, y_trn, verbose=1, epochs=2, batch_size=256)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1187, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 857, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 847, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 840, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 797, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1044, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 419, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 555, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1044, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\keras\\layers\\embeddings.py\", line 191, in call\n      out = embedding_ops.embedding_lookup_v2(self.embeddings, inputs)\nNode: 'model/sparse_seq_emb_hist_click_article_id/embedding_lookup_2'\nindices[0,0] = 183530 is not in [0, 16427)\n\t [[{{node model/sparse_seq_emb_hist_click_article_id/embedding_lookup_2}}]] [Op:__inference_train_function_4676]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "if offline:\n",
    "    history = model.fit(x_trn, y_trn, verbose=1, epochs=10, validation_data=(x_val, y_val) , batch_size=256)\n",
    "else:\n",
    "    # 也可以使用上面的语句用自己采样出来的验证集\n",
    "    # history = model.fit(x_trn, y_trn, verbose=1, epochs=3, validation_split=0.3, batch_size=256)\n",
    "    history = model.fit(x_trn, y_trn, verbose=1, epochs=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6 模型融合\n",
    "\n",
    "### 6.1 加权融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取多个模型的排序结果文件\n",
    "lgb_ranker = pd.read_csv(save_path + 'lgb_ranker_score.csv')\n",
    "lgb_cls = pd.read_csv(save_path + 'lgb_cls_score.csv')\n",
    "# din_ranker = pd.read_csv(save_path + 'din_rank_score.csv')\n",
    "\n",
    "# 这里也可以换成交叉验证输出的测试结果进行加权融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_model = {'lgb_ranker': lgb_ranker, \n",
    "              'lgb_cls': lgb_cls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensumble_predict_topk(rank_model: dict, topk: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    生成集成模型的前 K 个预测结果。\n",
    "\n",
    "    Args:\n",
    "        rank_model (`dict`): 包含多个模型的字典，必须包含 'lgb_cls'、'din_ranker' 和 'lgb_ranker'。\n",
    "        topk (`int`, optional): 每个用户推荐的文章数量，默认为 5。\n",
    "\n",
    "    Returns:\n",
    "        `None`: 该函数没有返回值，但会调用 `submit` 函数保存结果。\n",
    "    \"\"\"\n",
    "    # 合并 LightGBM 分类模型和 DIN 排序器的预测结果\n",
    "    final_recall = rank_model['lgb_cls']\n",
    "    # final_recall = rank_model['lgb_cls'].append(rank_model['din_ranker'])\n",
    "    \n",
    "    # 对 LightGBM 排序器的预测分数进行归一化处理\n",
    "    rank_model['lgb_ranker']['pred_score'] = rank_model['lgb_ranker']['pred_score'].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    # 合并所有模型的预测结果\n",
    "    final_recall = pd.concat([final_recall, rank_model['lgb_ranker']])\n",
    "    # final_recall = final_recall.append(rank_model['lgb_ranker'])\n",
    "    \n",
    "    # 按用户和文章 ID 分组，计算预测分数的总和\n",
    "    final_recall = final_recall.groupby(['user_id', 'click_article_id'])['pred_score'].sum().reset_index()\n",
    "    \n",
    "    # 调用提交函数，将结果保存为 CSV 文件\n",
    "    submit(final_recall, topk=topk, model_name='ensemble_fuse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Transform function failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mf:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\apply.py:314\u001b[0m, in \u001b[0;36mApply.transform_str_or_callable\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mapply(func, args\u001b[38;5;241m=\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03mInvoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03mdtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n",
      "File \u001b[1;32mf:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m, in \u001b[0;36mget_ensumble_predict_topk.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# final_recall = rank_model['lgb_cls'].append(rank_model['din_ranker'])\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m rank_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgb_ranker\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m rank_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgb_ranker\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mnorm_sim\u001b[49m(x))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# final_recall = final_recall.append(rank_model['lgb_ranker'])\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'norm_sim' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mf:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\apply.py:246\u001b[0m, in \u001b[0;36mApply.transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 246\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_str_or_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\apply.py:316\u001b[0m, in \u001b[0;36mApply.transform_str_or_callable\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m, in \u001b[0;36mget_ensumble_predict_topk.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# final_recall = rank_model['lgb_cls'].append(rank_model['din_ranker'])\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m rank_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgb_ranker\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m rank_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgb_ranker\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mnorm_sim\u001b[49m(x))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# final_recall = final_recall.append(rank_model['lgb_ranker'])\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'norm_sim' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ensumble_predict_topk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m, in \u001b[0;36mget_ensumble_predict_topk\u001b[1;34m(rank_model, topk)\u001b[0m\n\u001b[0;32m      2\u001b[0m final_recall \u001b[38;5;241m=\u001b[39m rank_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgb_cls\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# final_recall = rank_model['lgb_cls'].append(rank_model['din_ranker'])\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m rank_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgb_ranker\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mrank_model\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlgb_ranker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# final_recall = final_recall.append(rank_model['lgb_ranker'])\u001b[39;00m\n\u001b[0;32m      7\u001b[0m final_recall \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([final_recall, rank_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgb_ranker\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[1;32mf:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\series.py:4786\u001b[0m, in \u001b[0;36mSeries.transform\u001b[1;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   4781\u001b[0m ser \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   4783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mor\u001b[39;00m warn_copy_on_write()\n\u001b[0;32m   4784\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   4785\u001b[0m )\n\u001b[1;32m-> 4786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4787\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mf:\\anaconda\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\apply.py:250\u001b[0m, in \u001b[0;36mApply.transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransform function failed\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Functions that transform may return empty Series/DataFrame\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# when the dtype is not appropriate\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, (ABCSeries, ABCDataFrame))\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mempty\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mempty\n\u001b[0;32m    258\u001b[0m ):\n",
      "\u001b[1;31mValueError\u001b[0m: Transform function failed"
     ]
    }
   ],
   "source": [
    "get_ensumble_predict_topk(rank_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Stacking\n",
    "\n",
    "- 读取多个模型的交叉验证生成的结果文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集\n",
    "trn_lgb_ranker_feats = pd.read_csv(save_path + 'trn_lgb_ranker_feats.csv')\n",
    "trn_lgb_cls_feats = pd.read_csv(save_path + 'trn_lgb_cls_feats.csv')\n",
    "# trn_din_cls_feats = pd.read_csv(save_path + 'trn_din_cls_feats.csv')\n",
    "\n",
    "# 测试集\n",
    "tst_lgb_ranker_feats = pd.read_csv(save_path + 'tst_lgb_ranker_feats.csv')\n",
    "tst_lgb_cls_feats = pd.read_csv(save_path + 'tst_lgb_cls_feats.csv')\n",
    "# tst_din_cls_feats = pd.read_csv(save_path + 'tst_din_cls_feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将多个模型输出的特征进行拼接\n",
    "finall_trn_ranker_feats = trn_lgb_ranker_feats[['user_id', 'click_article_id', 'label']]\n",
    "finall_tst_ranker_feats = tst_lgb_ranker_feats[['user_id', 'click_article_id']]\n",
    "\n",
    "for idx, trn_model in enumerate([trn_lgb_ranker_feats, trn_lgb_cls_feats]):\n",
    "    for feat in [ 'pred_score', 'pred_rank']:\n",
    "        col_name = feat + '_' + str(idx)\n",
    "        finall_trn_ranker_feats[col_name] = trn_model[feat]\n",
    "\n",
    "for idx, tst_model in enumerate([tst_lgb_ranker_feats, tst_lgb_cls_feats]):\n",
    "    for feat in [ 'pred_score', 'pred_rank']:\n",
    "        col_name = feat + '_' + str(idx)\n",
    "        finall_tst_ranker_feats[col_name] = tst_model[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个逻辑回归模型再次拟合交叉验证产生的特征对测试集进行预测\n",
    "# 这里需要注意的是，在做交叉验证的时候可以构造多一些与输出预测值相关的特征，来丰富这里简单模型的特征\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "feat_cols = ['pred_score_0', 'pred_rank_0', 'pred_score_1', 'pred_rank_1']\n",
    "\n",
    "trn_x = finall_trn_ranker_feats[feat_cols]\n",
    "trn_y = finall_trn_ranker_feats['label']\n",
    "\n",
    "tst_x = finall_tst_ranker_feats[feat_cols]\n",
    "\n",
    "# 定义模型\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# 模型训练\n",
    "lr.fit(trn_x, trn_y)\n",
    "\n",
    "# 模型预测\n",
    "finall_tst_ranker_feats['pred_score'] = lr.predict_proba(tst_x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = finall_tst_ranker_feats[['user_id', 'click_article_id', 'pred_score']]\n",
    "submit(rank_results, topk=5, model_name='ensumble_staking')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
